{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1 - Machine Translation - MDS Computational Linguistics\n",
    "\n",
    "### Assignment Topics\n",
    "- Phrase Based Machine Translation\n",
    "- Multilingual Word Embeddings\n",
    "- MT datasets\n",
    "\n",
    "### Software Requirements\n",
    "- Python (>=3.6)\n",
    "- PyTorch (>=1.7.0) \n",
    "- Jupyter (latest)\n",
    "\n",
    "- GIZA++ Needs:\n",
    "    - Perl\n",
    "    - OSX/Linux (recommended) or a Cygwin Terminal\n",
    "    \n",
    "If you are installing GIZA++ on Cygwin, make sure you have Perl, make, and GCC/G++ installed when you install Cygwin (default installation does not include these)\n",
    "\n",
    "### Submission Info.\n",
    "- Due Date: February 27, 2021, 23:59:00 (Vancouver time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:1}\n",
    "\n",
    "To get the marks for tidy submission:\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T1 Build Romanian-English/English-Romanian GIZA++ alignments \n",
    "\n",
    "We can use the GIZA++ tool to automatically align vocabularies in two different languages using parallel corpora. This is useful for example in creating bilingual dictionaries or other term-based translation tasks. Because of the age of the tool (2001) and the complications with getting it working on modern computers, we suggest pair programming with your group to install and run it. *You will not need to generate alignments for the individual portions of this lab, they will be provided in the student data directory*\n",
    "\n",
    "In this group assignment you'll be working with GIZA++ to generate alignments based on the EuroParl corpus between English and Romanian. \n",
    "\n",
    "First, Download the En/Ro parallel corpus here: http://www.statmt.org/europarl/ and follow the procedure in the tutorial to create the aligned output from GIZA++.  Decrease the size of the file to 200,000 sentences to speed up the training time using the following unix command (where filename and newfilename are your original and truncated corpus respectively):\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "head -200000 filename > newfile_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1.1 Check your output\n",
    "rubric={accuracy:5}\n",
    "\n",
    "Were you able to get it to align appropriately? Copy the first three alignments out of your *.VA3.final files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Partner names:\n",
    "\n",
    "#Paste output here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: GIZA++ Warm Up\n",
    "\n",
    "For the following \"warm up\" questions, check that you are understanding GIZA++'s outputs.\n",
    "\n",
    "### 1.1 Interpretting GIZA++ results\n",
    "rubric={reasoning:2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these three sentences, which one does GIZA++ handle \"best\"? Explain how you should measure \"best\" with GIZA++\n",
    "\n",
    "###### A. Sentence pair (28) source length 7 target length 8 alignment score : 1.13908e-07\n",
    "- It is the case of Alexander Nikitin . =\n",
    "- NULL ({ }) Es ({ 1 2 }) el ({ 3 }) caso ({ 4 }) de ({ 5 }) Alexander ({ 6 }) Nikitin ({ 7 }) . ({ 8 }) \n",
    "\n",
    "###### B. Sentence pair (122) source length 6 target length 7 alignment score : 7.36437e-21\n",
    "- You did not call me either . =\n",
    "- NULL ({ }) Tampoco ({ 3 }) me ({ 5 }) ha ({ 2 }) nombrado ({ 4 6 }) usted ({ 1 }) . ({ 7 }) \n",
    "\n",
    "###### C. Sentence pair (115) source length 4 target length 7 alignment score : 8.73259e-12\n",
    "- There is no room for amendments . =\n",
    "- NULL ({ 2 5 }) No ({ 1 }) caben ({ 3 4 }) modificaciones ({ 6 }) . ({ 7 }) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 GIZA++ vocab \n",
    "rubric={reasoning:1}\n",
    "\n",
    "What do the two numbers represent in this sample GIZA++ vocab entry? (see europarl-es-en/giza_output/en-es.trn.trg.vcb from the tutorial)\n",
    "\n",
    "```\n",
    "45 producido 391\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put Your Answer Here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3a GIZA++ Translation Tables\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Below is a (partial) GIZA++ translation table for one of the words in the corpus. What is the word index in the target language that corresponds to the most likely translation of the source term? [Note this should look bad on GitHub but fine in a jupyter notebook]\n",
    "\n",
    "*Hint:You should understand what the three numbers of each row represent.* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6 5 0.344281  \n",
    "6 6 0.0051642  \n",
    "6 70 0.360418  \n",
    "6 164 2.0722e-07  \n",
    "6 242 0.00264185  \n",
    "6 269 1.49345e-05  \n",
    "6 350 1.24741e-07  \n",
    "6 408 0.00296726  \n",
    "6 422 0.00269407  \n",
    "6 433 9.45562e-05  \n",
    "6 450 0.00538036  \n",
    "6 452 0.00269633  \n",
    "6 492 0.00272651  \n",
    "6 516 9.83587e-06  \n",
    "6 613 0.0026897  \n",
    "6 747 0.00478991  \n",
    "6 762 0.0162501  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put Your Answer Here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3b GIZA++ Translation Tables\n",
    "rubric={reasoning:1}\n",
    "\n",
    "In the above translation table, is the vocab index (6) coming from the source vocab or target vocab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Build a bilingual dictionary\n",
    "rubric={accuracy:3,quality:3,efficiency:3}\n",
    "\n",
    "Using the provided alignment files (see /data/lab1) covering En/Fr alignments, create a program to build a bilingual French-English/English-French dictionary, the dictionary should be a function that takes in a word and a language argument and returns the (single) most likely word based on the GIZA++ alignment. Comment your code, create appropriate test cases and catch errors.\n",
    "\n",
    "*Hint: Think about subtle issues with the generation of the alignments, for instance how should you handle situations where you have a rare word in one language that matches with a common word in the other language and vice versa?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code below, strongly suggested to implement as a CLASS\n",
    "\n",
    "def myDictionary(word, language):\n",
    "    ## to complete\n",
    "    return alignment_word\n",
    "\n",
    "# or \n",
    "\n",
    "class myDictionary():\n",
    "    def __init__(self):  #add arguments you'll need to initialize correctly\n",
    "        ## to complete\n",
    "    def lookup(word, language):  \n",
    "        ## to complete\n",
    "        return alignment_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Test cases\n",
    "rubric={accuracy:1}\n",
    "\n",
    "To the provided entries, provide additional test cases to ensure that the dictionary functions correctly. Consider words that shouldn't exist in a language, number of entries returned etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change to class implementation (e.g. foo.lookup(bar, baz)) if you decided to use that instead.\n",
    "print(myDictionary(\"vous\",language=\"french\"))\n",
    "print(myDictionary(\"Minutes\",language=\"english\"))\n",
    "print(myDictionary(\"awesome\",language=\"french\"))\n",
    "## Additional testing below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Explanation\n",
    "\n",
    "If your testing catches some subtle errors (i.e. it runs fine for the most part but in some edge cases translation errors occur), explain what the issue is and how you should fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Response here IF NEEDED*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Neural Language Alignment\n",
    "\n",
    "We compare GIZA++'s alignment with MUSE to see how purely statistical models compare with neural models.\n",
    "\n",
    "First get the English and French aligned word embeddings from https://github.com/facebookresearch/MUSE\n",
    "\n",
    "Next some libraries for visualizing things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cosine Similarity\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Cosine similarity is used fairly frequently in NLP to show distance or similarity between two vectors (and thus two words or embeddings etc).\n",
    "\n",
    "$similarity = cos(\\theta) = \\frac{A \\cdot B}{||A|| ||B||} = \\frac{\\sum_{i=1}^{d} A_iB_i}{\\sqrt{\\sum_{i=1}^{d} A^2_i}\\sqrt{\\sum_{i=1}^{d} B^2_i}}$\n",
    "\n",
    "Using the following two tensors (of a dim=3 embedding) show **by hand** how you would calculate the cosine similarity between these two vectors.\n",
    "\n",
    "A = [ 0.1010, -1.1388, -0.7991]\n",
    "\n",
    "B = [ 0.5083, -0.2255,  1.9037]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write Answer Here** (alternatively take a picture of your work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plotting Aligned Embeddings\n",
    "rubric={accuracy:2}\n",
    "\n",
    "For the following set of words: \"excessively\", \"Minutes\", \"citizens\", \"standards\", and \"disaster\" create a 2D diagram showing the words in vector space alongside their French closest 'equivalents'. *Use Load_vec and getnn functions from the colab notebook and feel free to use [this MUSE tutorial](https://github.com/facebookresearch/MUSE/blob/master/demo.ipynb) as a reference for how you can plot these embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code/diagram goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Comparing MUSE to GIZA++\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Based on the words that you have identified, how do the MUSE pre-trained embeddings compare with the GIZA++ mappings? Which method do you think works better in practice? What might be some drawbacks of this comparison?\n",
    "\n",
    "\n",
    "*Hint:You can perform a case-study to compare the alignment dictionary.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer Goes Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: MUSE from scratch \n",
    "\n",
    "We sort of cheated in Exercise 3 with using the pre-aligned embeddings, unfortunately these are trained on Wikipedia, and thus not a great comparison to the Europarl corpus dictionary we've made with GIZA++. We've provided a Google colab notebook in the repo 531_L1_MUSE.ipynb which should setup the environment correctly for running these on Google's colab platform.\n",
    "\n",
    "\n",
    "### 4.1 Create Fastext word embeddings for Europarl \n",
    "rubric={accuracy:3}\n",
    "\n",
    "FasText is similar to Word2Vec, but has some slight improvements (e.g. it can capture orthographic information). It is located as it:\n",
    "https://github.com/facebookresearch/fastText and then follow the instructions to train an embedding model for the English and French Europarl corpuses you downloaded earlier for 2.1.\n",
    "\n",
    "Copy your training procedure below as well as give example outputs for the closest words to \"Minutes\", \"minutes\", and \"vote\" for English and \"vous\", \"intervienne\", and \"accord\" for French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your training code goes here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give example outputs for the suggested words: \"Minutes\", \"minutes\", and \"vote\" for English and \"vous\", \"intervienne\", and \"accord\" for French."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Use MUSE to align the word embeddings \n",
    "rubric={accuracy:2}\n",
    "\n",
    "Using MUSE's unsupervised functionality, align the two language embedding spaces and find the closest French words that match the English words \"disaster\", \"vote\", and \"excessively\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Put your output here from the similarity check for the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.3 Compare MUSE with GIZA++\n",
    "rubric={reasoning:3}\n",
    "\n",
    "Based on the aligned dictionaries you've made, qualitatively does there seem to be much difference between GIZA++ and MUSE? Which one appears to work better? Write a brief (2-3 sentence) comparison of both the process to make the two dictionaries and the ultimate quality of the final dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Conceptual Questions\n",
    "\n",
    "### 5.1 Data Sets\n",
    "rubric={reasoning:3}\n",
    "\n",
    "Aligned corpuses are vital when it comes to creating a Machine Translation model. We used Europarl for this assignment, but you should think about your language needs if you are planning on working on projects dealing with non-European languages or other genres of text. Find two datasets that you might be interested in using for this unit. \n",
    "\n",
    "One important resource for this is the [Linguistics Data Consortium](https://catalog.ldc.upenn.edu/search) of which UBC is a member. To access the datasets that UBC has available please use [Abacus](https://resources.library.ubc.ca/page.php?details=abacus&id=1114)  (Recommended that you search on the LDC website, which has a better metadata search engine for the datasets, make sure you find something that has a parallel translation, and then locate the dataset on Abacus by searching for the title of it. Note UBC has most, but not all of the sets)\n",
    "\n",
    "\n",
    "For these two corpuses please identify:\n",
    "\n",
    "- What language pair(s) are covered by the corpus\n",
    "- Size of the corpus\n",
    "- \"Style\" of text covered (is it formal text? news writing? email? informal social media posts?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response goes here**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
